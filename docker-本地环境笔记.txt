#vagrant部分#
vagrant box add [自定义vagrantNAME] virtual.box #添加box
vagrant init [vagrantNAME] #初始化vagrant
vagrant up #启动vagrant



docker image ls #查看镜像
docker images   #查看镜像
docker version   #查看docker 版本
<<<<<<< HEAD
#将vagrant加入docker组#
=======
#将vagrant加入dockerzu#
>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
sudo groupadd docker
sudo gpasswd -a vagrant docker
sudo service docker restart

docker pull hello-world #从docker库拉取镜像

docker run [image-name]#启动容器
#Dockerfile#
FROM stratch     #制作BASE IMAGES   
FROM centos     #使用BASE IMAGES
LABEL maintainer="david@qq.com"    #注释
LABEL version="1.0"	              #注释
LABEL description="This is description"#注释

RUN    yum -y install  vim && touch test.php \
    	mv test.php text.php \   #运行命令 --------执行一次就要生成一层layer,所有尽可能写一行&& 隔开
WORKDIR                    #设定当前工作的目录，如果没有，自动创建目录，用WORKDIR ,不要使用RUN cd 尽量使用绝对目录

ADD hello  /    #添加文件到docker ,大部分情况，COPY由于ADD，添加远程文件/目录使用  RUN curl/wget
ADD test.tar.gz /       #添加到根目录并加压
DOPY  hello   test/ 
ENV    MYSQL_VERSION 5.6      #设置常量 ，尽量使用ENV增加可维护性
RUN apt-get install -y mysql-server="{MYSQL_VERSION}" \
         && rm -rf /var/lib/apt/lists/*      #引用常量
RUN                  #执行命令并创建新的IMAGE LAYER
CMD                  #设置容器启动后默认执行的命令和参数,如果docker run 指定了其他命令，CMD命令会被忽略，如果定义了多个CMD，只有最后一个会执行
ENTRYPOINT     #设置容器启动时运行的命令，让容器以应用程序或者服务的形式运行，不会被忽略，一定会执行，最佳实践：写一个shell脚本作为entrypoint  ENTRYPOINT ["docker.sh"]
VOLUME               #存储
EXPOSE                 #网络
<<<<<<< HEAD

=======
>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
docker build -t david/hello-world . #创建镜像
docker history [imageID]        #查看docker分层
docker run [imageNAME]       #创建container
docker container ls                 #查看正在运行容器


<<<<<<< HEAD
=======

>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
shell格式
RUN apt-get install -y vim
exec格式
RUN ["apt-get", "install","-y","vim"]
docker container ls -a             #查看所有容器
docker ps -a                            #查看所有容器


docker run -it centos              #交互式方式运行容器

docker container rm [containerID]    #删除container
docker rm                      #默认删除就是contain

docker image rm [imageID/imageNAME]   #删除镜像
docker rmi                                                   #删除镜像

docker container ls -aq                                #列出容器ID
docker container ls -a | awk {'print$1'}         #列出容器ID
docker rm $(docker container ls -aq)           #删除所有容器
docker container ls -f "status=exited" -q      #列出所有退出的容器
docker rm $(docker container ls -f "status=exited" -q)       #列出所有退出的容器


docker container commit     [containerNAME]        [tagNAME]                #把修改的容器生成新的容器(把container 创建新的image)
docker commit                                             #把修改的容器生成新的容器(把container 创建新的image)


docker image build -t  [tagNAME]                          #创建新的镜像
docker build               			#创建新的镜像

docker login     #登陆docker-hub
docker image push   [imageNAME]    #image 分发 推到docker-hub
docker push    [imageNAME]             #image分发，推到docker-hub
docker pull  [imageNAME]                #从docker-hub拉取imge

docker run -d -p 5000:5000 --restart always --name registry registry:2 #通过image创建本地image库
#push在/etc/docker下vi daemon.json 写入{["insecure-registries":["10.75.44.222:5000"]} 
然后vi /lib/systemd/system/docker.service 加入一行EnvironmentFile=-/etc/docker/daemon.json
然后sudo service docker restart#

#
查看是否PUSH到本地库成功，docker提供了API 0.0.0.0:0000/v2/.catlog
详见docker官网文档
#
#把python程序打造成image#
#Dockerfile
FROM python:2.7
LABEL maitainer = "david"
RUN pip install flask 
COPY app.py /app
EXPOSE 5000
CMD ["python","app.py"]
#调试docker---进入到临时生成的image查看相应的错误步骤#
docker run -it ["临时生成的imageID"] /bin/bash     #常驻内存的程序

<<<<<<< HEAD
=======




>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
#对运行中的容器执行命令
docker exec -it [containerID]例11duid555444 [command]例/bin/bash  #交互式的在运行中容器中执行命令
docker exec -it 11q8en3398d ip a #打印IP
docker container stop      #停止运行的容器
docker stop 	         #停止运行的容器
docker container start      #启动容器
docker start	         #启动容器
docker run -d -name=demo david/vim  #给容器自定义一个名字


docker inspect  [containerNAME] #显示出container详细的信息
docker logs  [containerID]            #容器的运行信息


<<<<<<< HEAD
=======



>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
#压力测试#
stress --vm 1 --vm-bytes 50000M  --verbose
#创建压力测试Dockerfile#
FROM ubuntu
RUN apt-get update && apt-get -y install
ENTRYPOINT ["/use/bin/stress"]
CMD []      #留空表示可以在外部传值
docker build -t david/stress
docker run -it [imageNAME] --vm 1 --verbose #run 加上命令参数#命令行工具




#######namespace############################
<<<<<<< HEAD
docker run -d --name test1 busybox /bin/bash -c "while true; do sleep 3600 done"   
=======
docker run -d --name test1 busybox /bin/sh -c "while true; do sleep 3600; done"   
>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
后台运行busybox,起名字test1,运行一个命令while循环
sudo ip netns list ##查看本机的network namespace
sudo ip netns delete [networkNAME] ##删除
sudo ip netns add [networkNAME]    ##添加
sudo ip netns exec [networkNAME] ip a#在[networkNAME]namespace里执行 ip a 命令
sudo ip netns exec [networkNAME] ip link #在[networkNAME]namespace里执行 ip link 命令
sudo ip netns exec [networkNAME] ip link set dev lo up#在[networkNAME]namespace里执行 ip link set dev lo up 命令

<<<<<<< HEAD
#创建linux veth 虚拟线#
sudo ip link add veth-test1 type veth peer name veth-test2
#给namespace添加veth#
sudo ip link set veth-test2 netns test2
sudo ip link set veth-test1 netns test1
#查看test1的link#
sudo ip netns exec test1 ip link
#给veth添加ip#
sudo ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2
sudo ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1
#set namespace up#
sudo ip netns exec test2 ip link set dev veth-test2 up
sudo ip netns exec test1 ip link set dev veth-test1 up
#查看namespace#
sudo ip netns exec test1 ip link
sudo ip netns exec test1 ip a
#列出当前docker都有哪些网络#
sudo docker network ls
#创建虚拟网卡详解#
brctl
sudo yum install bridge-utils
#--linke test1给test添加一条DNS记录#
sudo docker run -d --name test2 --link test1 busybox /bin/sh "echo hello world"
#新建一个network#-d 指定driver [自定义名称]
sudo docker network create  -d bridge my-bridge
#查看network#
sudo docker network ls
#指定--network 启动docker#
docker run -d --name test3 --network my-bridge busybox
/bin/sh -c "while true; do sleep 3600; done"
#修改docker的network#
sudo docker network connect [networkNAME] [containerNAME]
#查看docker的ip#
sudo docker inspect bridge 
#docker 端口映射#-p
 sudo docker run --name web -d -p 80:80 nginx
=======





#创建linux veth 虚拟线#
sudo ip link add veth-test1 type veth peer name veth-test2


#给namespace添加veth#
sudo ip link set veth-test2 netns test2
sudo ip link set veth-test1 netns test1


#查看test1的link#
sudo ip netns exec test1 ip link


#给veth添加ip#
sudo ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2
sudo ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1



#set namespace up#
sudo ip netns exec test2 ip link set dev veth-test2 up
sudo ip netns exec test1 ip link set dev veth-test1 up



#查看namespace#
sudo ip netns exec test1 ip link
sudo ip netns exec test1 ip a



#列出当前docker都有哪些网络#
sudo docker network ls



#创建虚拟网卡详解#
brctl
sudo yum install bridge-utils



#--linke test1给test添加一条DNS记录#
sudo docker run -d --name test2 --link test1 busybox /bin/sh "echo hello world"



#新建一个network#-d 指定driver [自定义名称]
sudo docker network create  -d bridge my-bridge



#查看network#
sudo docker network ls


#指定--network 启动docker#
docker run -d --name test3 --network my-bridge busybox
/bin/sh -c "while true; do sleep 3600; done"


#修改docker的network#
sudo docker network connect [networkNAME] [containerNAME]


#查看docker的ip#
sudo docker inspect bridge 


#docker 端口映射#-p
 sudo docker run --name web -d -p 80:80 nginx


>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
#查看docker环境信息#
docker-machine env [dockerNAME]
#在本地操作线上的docker#
#复制docker 环境信息的eval信息到本地命令行即可#
#例eval $(docker-machine env imooc)
#network类型之none和host# --network指定network类型
#none类型是孤立的，只能通过sudo docker exec -it [dockerNAME] /bin/sh 方式进入，使用场景，放置不希望被访问的机密信息
#host类型是没有自己独立的network，共享主机的network
sudo docker run -d --name test1 --network none busybox /bin/sh -c "while true: do sleep 3600; done"

<<<<<<< HEAD
#解决vagrant virtualbox不能共享文件夹-可以通过virtualbox手动添加共享文件夹#
1.安装系统镜像 
=======
#解决vagrant virtualbox不能共享文件夹#
1.安装系统镜像
>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
2.登入到系统
3.sudo yum update
4.sudo yum -y install wget kernel-devel     kernel-headers    gcc  gcc-c++ make  
5.sudo wget http://download.virtualbox.org/virtualbox/5.2.8/VBoxGuestAdditions_5.2.8.iso
6.sudo mount -t iso9660 -o loop VBoxGuestAdditions_5.2.8.iso /mnt/os
7.cd /mnt/os
8.sudo ./VBoxLinuxAdditions.run 
9.sudo reboot
10.sudo mount -t vboxsf [共享文件夹名称] [虚拟机文件夹]
<<<<<<< HEAD


#解决vagrant不能共享文件夹的问题-脚本自动关联共享文件夹#
vagrant plugin install vagrant-vbguest

#多容器复杂应用的部署#
sudo docker build david/flask-redis #build image
sudo docker run -d -link redis --name flask-redis -e REDIS_HOST=redis david/flask-redis #--link 通过名字访问 -e指在启动的容器中设置一个环境变量

vagrant plugin install vagrant scp ##vagrant 安装插件

=======
 


#多容器复杂应用的部署#
sudo docker run -d --name redis redis
sudo docker build david/flask-redis #build image
sudo docker run -d -link redis --name flask-redis -e REDIS_HOST=redis david/flask-redis #--link 通过名字访问 -e指在启动的容器中设置一个环境变量


多机多容器部署
# Mutil-host networking with etcd

## setup etcd cluster

在docker-node1上

```
vagrant@docker-node1:~$ wget https://github.com/coreos/etcd/releases/download/v3.0.12/etcd-v3.0.12-linux-amd64.tar.gz
vagrant@docker-node1:~$ tar zxvf etcd-v3.0.12-linux-amd64.tar.gz
vagrant@docker-node1:~$ cd etcd-v3.0.12-linux-amd64
vagrant@docker-node1:~$ nohup ./etcd --name docker-node1 --initial-advertise-peer-urls http://192.168.205.10:2380 \
--listen-peer-urls http://192.168.205.10:2380 \
--listen-client-urls http://192.168.205.10:2379,http://127.0.0.1:2379 \
--advertise-client-urls http://192.168.205.10:2379 \
--initial-cluster-token etcd-cluster \
--initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \
--initial-cluster-state new&
```


在docker-node2上

```
vagrant@docker-node2:~$ wget https://github.com/coreos/etcd/releases/download/v3.0.12/etcd-v3.0.12-linux-amd64.tar.gz
vagrant@docker-node2:~$ tar zxvf etcd-v3.0.12-linux-amd64.tar.gz
vagrant@docker-node2:~$ cd etcd-v3.0.12-linux-amd64/
vagrant@docker-node2:~$ nohup ./etcd --name docker-node2 --initial-advertise-peer-urls http://192.168.205.11:2380 \
--listen-peer-urls http://192.168.205.11:2380 \
--listen-client-urls http://192.168.205.11:2379,http://127.0.0.1:2379 \
--advertise-client-urls http://192.168.205.11:2379 \
--initial-cluster-token etcd-cluster \
--initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \
--initial-cluster-state new&
```

检查cluster状态

```
vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl cluster-health
member 21eca106efe4caee is healthy: got healthy result from http://192.168.205.10:2379
member 8614974c83d1cc6d is healthy: got healthy result from http://192.168.205.11:2379
cluster is healthy
```

## 重启docker服务


在docker-node1上

```
$ sudo service docker stop
$ sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.10:2379 --cluster-advertise=192.168.205.10:2375&
```

在docker-node2上

```
$ sudo service docker stop
$ sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.11:2379 --cluster-advertise=192.168.205.11:2375&
```

## 创建overlay network

在docker-node1上创建一个demo的overlay network

```
vagrant@docker-node1:~$ sudo docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
0e7bef3f143a        bridge              bridge              local
a5c7daf62325        host                host                local
3198cae88ab4        none                null                local
vagrant@docker-node1:~$ sudo docker network create -d overlay demo
3d430f3338a2c3496e9edeccc880f0a7affa06522b4249497ef6c4cd6571eaa9
vagrant@docker-node1:~$ sudo docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
0e7bef3f143a        bridge              bridge              local
3d430f3338a2        demo                overlay             global
a5c7daf62325        host                host                local
3198cae88ab4        none                null                local
vagrant@docker-node1:~$ sudo docker network inspect demo
[
    {
        "Name": "demo",
        "Id": "3d430f3338a2c3496e9edeccc880f0a7affa06522b4249497ef6c4cd6571eaa9",
        "Scope": "global",
        "Driver": "overlay",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "10.0.0.0/24",
                    "Gateway": "10.0.0.1/24"
                }
            ]
        },
        "Internal": false,
        "Containers": {},
        "Options": {},
        "Labels": {}
    }
]
```

我们会看到在node2上，这个demo的overlay network会被同步创建

```
vagrant@docker-node2:~$ sudo docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
c9947d4c3669        bridge              bridge              local
3d430f3338a2        demo                overlay             global
fa5168034de1        host                host                local
c2ca34abec2a        none                null                local
```

通过查看etcd的key-value, 我们获取到，这个demo的network是通过etcd从node1同步到node2的

```
vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl ls /docker
/docker/network
/docker/nodes
vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl ls /docker/nodes
/docker/nodes/192.168.205.11:2375
/docker/nodes/192.168.205.10:2375
vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl ls /docker/network/v1.0/network
/docker/network/v1.0/network/3d430f3338a2c3496e9edeccc880f0a7affa06522b4249497ef6c4cd6571eaa9
vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl get /docker/network/v1.0/network/3d430f3338a2c3496e9edeccc880f0a7affa06522b4249497ef6c4cd6571eaa9 | jq .
{
  "addrSpace": "GlobalDefault",
  "enableIPv6": false,
  "generic": {
    "com.docker.network.enable_ipv6": false,
    "com.docker.network.generic": {}
  },
  "id": "3d430f3338a2c3496e9edeccc880f0a7affa06522b4249497ef6c4cd6571eaa9",
  "inDelete": false,
  "ingress": false,
  "internal": false,
  "ipamOptions": {},
  "ipamType": "default",
  "ipamV4Config": "[{\"PreferredPool\":\"\",\"SubPool\":\"\",\"Gateway\":\"\",\"AuxAddresses\":null}]",
  "ipamV4Info": "[{\"IPAMData\":\"{\\\"AddressSpace\\\":\\\"GlobalDefault\\\",\\\"Gateway\\\":\\\"10.0.0.1/24\\\",\\\"Pool\\\":\\\"10.0.0.0/24\\\"}\",\"PoolID\":\"GlobalDefault/10.0.0.0/24\"}]",
  "labels": {},
  "name": "demo",
  "networkType": "overlay",
  "persist": true,
  "postIPv6": false,
  "scope": "global"
}
```


## 创建连接demo网络的容器

在docker-node1上

```
vagrant@docker-node1:~$ sudo docker run -d --name test1 --net demo busybox sh -c "while true; do sleep 3600; done"
Unable to find image 'busybox:latest' locally
latest: Pulling from library/busybox
56bec22e3559: Pull complete
Digest: sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912
Status: Downloaded newer image for busybox:latest
a95a9466331dd9305f9f3c30e7330b5a41aae64afda78f038fc9e04900fcac54
vagrant@docker-node1:~$ sudo docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
a95a9466331d        busybox             "sh -c 'while true; d"   4 seconds ago       Up 3 seconds                            test1
vagrant@docker-node1:~$ sudo docker exec test1 ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:0A:00:00:02
          inet addr:10.0.0.2  Bcast:0.0.0.0  Mask:255.255.255.0
          inet6 addr: fe80::42:aff:fe00:2/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1
          RX packets:15 errors:0 dropped:0 overruns:0 frame:0
          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:1206 (1.1 KiB)  TX bytes:648 (648.0 B)

eth1      Link encap:Ethernet  HWaddr 02:42:AC:12:00:02
          inet addr:172.18.0.2  Bcast:0.0.0.0  Mask:255.255.0.0
          inet6 addr: fe80::42:acff:fe12:2/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:648 (648.0 B)  TX bytes:648 (648.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)

vagrant@docker-node1:~$
```

在docker-node2上

```
vagrant@docker-node2:~$ sudo docker run -d --name test1 --net demo busybox sh -c "while true; do sleep 3600; done"
Unable to find image 'busybox:latest' locally
latest: Pulling from library/busybox
56bec22e3559: Pull complete
Digest: sha256:29f5d56d12684887bdfa50dcd29fc31eea4aaf4ad3bec43daf19026a7ce69912
Status: Downloaded newer image for busybox:latest
fad6dc6538a85d3dcc958e8ed7b1ec3810feee3e454c1d3f4e53ba25429b290b
docker: Error response from daemon: service endpoint with name test1 already exists.
vagrant@docker-node2:~$ sudo docker run -d --name test2 --net demo busybox sh -c "while true; do sleep 3600; done"
9d494a2f66a69e6b861961d0c6af2446265bec9b1d273d7e70d0e46eb2e98d20
```


验证连通性。

```
vagrant@docker-node2:~$ sudo docker exec -it test2 ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:0A:00:00:03
          inet addr:10.0.0.3  Bcast:0.0.0.0  Mask:255.255.255.0
          inet6 addr: fe80::42:aff:fe00:3/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1
          RX packets:208 errors:0 dropped:0 overruns:0 frame:0
          TX packets:201 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:20008 (19.5 KiB)  TX bytes:19450 (18.9 KiB)

eth1      Link encap:Ethernet  HWaddr 02:42:AC:12:00:02
          inet addr:172.18.0.2  Bcast:0.0.0.0  Mask:255.255.0.0
          inet6 addr: fe80::42:acff:fe12:2/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:648 (648.0 B)  TX bytes:648 (648.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)

  vagrant@docker-node1:~$ sudo docker exec test1 sh -c "ping 10.0.0.3"
  PING 10.0.0.3 (10.0.0.3): 56 data bytes
  64 bytes from 10.0.0.3: seq=0 ttl=64 time=0.579 ms
  64 bytes from 10.0.0.3: seq=1 ttl=64 time=0.411 ms
  64 bytes from 10.0.0.3: seq=2 ttl=64 time=0.483 ms
  ^C
  vagrant@docker-node1:~$
```





vagrant plugin install vagrant scp ##vagrant 安装插件





>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
#docker持久化volume#
VOLUME [/var/lib/mysql] #Dockerfile定义持久化的路径
sudo docker run -d --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql #安装mysql需要密码参数#
sudo docker volume ls #查看volume#
sudo docker volume [volumeID]#删除volume#
sudo docker volume inspect [volumeID] #查看volume详情#
sudo docker run -d --name mysql1 -v mysql:/var/lib/mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql # -e设置mysql为空密码，-v 给volume起别名/使用之前的volume
<<<<<<< HEAD

=======
#解决vagrant不能共享文件夹的问题#
vagrant plugin install vagrant-vbguest
>>>>>>> 83c1d353b0dbbec274fd45ad67328c742150fc4a
#数据持久化bind mouting#
docker -v /home/aaa:/root /aaa#指定本地目录和docker目录的对应关系
docker run -d -p 80:80 --name web david/nginx #启动一个nginx docker
docker run -d -v $(pwd):/usr/share/nginx/html -p 80:80 --name web david/nginx #启动一个nginx docker -v 将当前目录映射到物理机的指定目录$(pwd)虚拟机当前的目录

#docker compose#

docker run -d --name mysql -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASES=wordpess #启动mysql 设置密码和数据库名
docker run -d -e WORDPRESS_DB_HOST=mysql:3306 --link mysql -p 8080:80 wordpress #启动WordPress设置数据库为mysql 

#docker compose#
#介绍#
verseion 3 #版本号

services  #三大部分

volumes  #三大部分

networks  #三大部分
#docker composer安装，mac windows默认安装，linux需要安装
sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose --version
#配置文件  ----xxxy.yml#
#命令#
docker-compose up #创建容器
docker-compose ps #查看docker-compose启动的容器状态
docker-compose start/stop #开始/停止
docker-compose down ##停止容器，删除容器和网络
docker-compose images #列出docker-compose的image
docker-compose exec [serviceNAME]#在容器执行命令
#docker-compose.yml实例#
version: "3"
services:
 redis:
  image:redis
 web:
  build:
   context:
   dockerfile:Dockerfile
  ports:
   -8000:5000
  environment:
   REDIS_HOST:redis
#docker-compose水平扩展和负载均衡#
docker-compose up --scale SERVICE=NUM
docker-compose u --scale web=3 -d ##实例
#for循环脚本#
for i in 'seq 10'; do curl 127.0.0.1:8080; done
#docker-compose build #docker-compose build 镜像
#docker-compose用于本地开发的环境，不适用于生产环境#